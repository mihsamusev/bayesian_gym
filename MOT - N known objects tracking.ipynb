{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tracking n objects\n",
    "The SOT model developed previously was only capable of tracking a single object and estimate its state $x_k$ in clutter and missed detections. Generalization of SOT is the ability to track $n$ objects and estimate the state matrix $X_k = [x_k^1, x_k^2,...,x_k^n]$ where $n$ is assumed to be both known and constant. The clutter and the missed detections will be included as well. The crux of $n$ object tracking is handling many data association problem. \n",
    "\n",
    "New models required for the problem are:\n",
    "\n",
    "- model for the measurements from all $n$ objects and the clutter\n",
    "- model the motion of all $n$ objects\n",
    "- prior for the states of the $n$ objects\n",
    "- methods for handling the data association\n",
    "\n",
    "As well as new algorithms:\n",
    "\n",
    "- Global Nearest Neigbour (GNN) filter\n",
    "- Joint Probablistic Data Association (JPDA) filter\n",
    "- Multi Hypothesis Tracker (MHT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measurement modelling\n",
    "Similarly to the SOT the measurement matrix  $Z_k = \\Pi(O_k, C_k)$ is a random permutation between the clutter measurements $C_k$ and object detections $O_k$. Similarly to SOT the clutter is Poisson point process with intensity $\\lambda_c(c) = \\bar{\\lambda}_cf_c(c)$ depending on the clutter rate and the spatial PFD. The object detections, however, are now $O_k = [O_k^1,...O_k^i,...,O_k^n]$. Nevertheless, for $O_k^i$ same measurement model as in SOT applies, namely:\n",
    "$$\n",
    "\\begin{cases}\n",
    "O_k^i = [] & \\text{ with probability } 1 - P^D(x_k^i) \\\\\n",
    "O_k^i = o_k^i & \\text{ with probability } P^D(x_k^i) \\text{ and likelihood } g_k(o_k^i|x_k^i)\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "How does the n - object measurement likelihood $p(Z_k|X_k)$ looks in this case? Similarly to the SOT, the measurement likelihood can be build introducing the hypotheses variable and applying the law of total probability.\n",
    "\n",
    "$$\n",
    "p(Z|x) = p(Z,m|x) = \\sum_{\\theta=0}^{m}p(Z,m,\\theta|x) = \\sum_{\\theta=0}^{m}p(Z|m,\\theta,x)p(\\theta,m|x)\n",
    "$$\n",
    "\n",
    "Lets take it part by part again and derive the components\n",
    "\n",
    "- Association conditioned measurement model $p(Z|m,\\theta,x)$\n",
    "- Assication prior $p(\\theta,m|x)$\n",
    "\n",
    "### Data association variable $\\theta$\n",
    "For the measurements  $Z_k = [Z_k^1,...Z_k^i,...,Z_k^n]$ the $\\theta_k^i$ is the association for the object with state $x_k^i$ such that:\n",
    "\n",
    "$$ \\theta_k^i =\n",
    "\\begin{cases}\n",
    "j & \\text{ of object }i\\text{is associated to measurement}j\\\\\n",
    "0 & \\text{ if object is undetected}\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
